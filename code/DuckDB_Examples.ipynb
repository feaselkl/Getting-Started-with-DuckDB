{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB Demo Code\n",
    "\n",
    "This notebook serves as an introduction to DuckDB, using the Python API. In the event that you are running this notebook separately, you will want to perform the following setup steps.\n",
    "\n",
    "## Setup Steps\n",
    "\n",
    "I [highly recommend you set up a virtual environment](https://youtu.be/Th9Noj_078A). If you choose not to use a virtual environment, the demos will still work as expected, assuming there are no Python package version conflicts.\n",
    "\n",
    "All of the requirements are in `code\\requirements.txt`.\n",
    "\n",
    "Links to where you can get all of the data are available in `data\\DataLocations.txt`. For these demos, I store data in a folder called `duckdbdata\\`. This folder is **not** in source control, so you will need to create it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules and Connections\n",
    "\n",
    "There are two ways to use DuckDB in Python: direct access via the `duckdb` module or access via a connection. If you are familiar with the way connections happen in .NET using, for example, ADO, you know that there is a multi-step process:\n",
    "\n",
    "1. Open the connection.\n",
    "2. Using the open connection, send one or more commands.\n",
    "3. Close the connection.\n",
    "\n",
    "DuckDB's Python API allows this, but it also allows us to perform direct access. For example, these two commands are, in many respects, the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT 42 as X\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.sql(\"SELECT 42 as X\").show()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, why create a connection? There are a few important reasons:\n",
    "\n",
    "1. `duckdb.sql()` runs commands against an in-memory database, rather than against a specific file. No tables persist to disk.\n",
    "2. Creating a connection **may** run commands against an in-memory database, or against a database on disk. In the example above, we used `duckdb.connect()`, which still uses an in-memory database. But we can include a filename as a parameter and write to disk.\n",
    "3. The `duckdb.sql()` commands run against a **shared global database**, meaning that if you are running multiple processes that each use DuckDB in non-connection mode, they write to the same in-memory database. This might cause unexpected conflicts due to matching names.\n",
    "\n",
    "In general, use connections. There may be specific circumstances in which the global `duckdb.sql()` module is necessary, but they are fairly uncommon.\n",
    "\n",
    "You can also maintain a connection and auto-close it using the `with` keyword. This closure allows the connection to be open until the end of the `with` block, after which Python closes the connection automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(\"../duckdbdata/file.db\") as con:\n",
    "    con.sql(\"CREATE OR REPLACE TABLE test (i INTEGER)\")\n",
    "    con.sql(\"INSERT INTO test VALUES (42)\")\n",
    "    con.table(\"test\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data\n",
    "\n",
    "The dataset we will use is a dataset of parking tickets from the city of Chicago, covering nearly two decades. The data is available thanks to Daniel Hutmacher, who [converted an open dataset into a well-designed SQL Server database](https://sqlsunday.com/2022/12/05/new-demo-database/). I have extracted much of this data into a Parquet file, and we will use that for demos.\n",
    "\n",
    "If you do not already have a `chicago.db` file, this will create a new, empty file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(\"../duckdbdata/chicago.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the data from the Chicago Parking Tickets parquet file. This file is approximately 2GB in size and is available from the link in `data\\DataLocations.txt`. Be sure to put it in a directory called `/duckdbdata` at the same level as the `/code` directory, or change the command to match where you have downloaded the file.\n",
    "\n",
    "This uses Pandas to read the Parquet file into a Pandas DataFrame. DuckDB natively supports Pandas and Polars DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"../duckdbdata/ChicagoParkingTickets.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load a new table called `ChicagoParkingTickets` from the DataFrame we have loaded.\n",
    "\n",
    "As a side note, notice that `CREATE OR REPLACE TABLE` and `CREATE TABLE IF NOT EXISTS` are both valid syntax for DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"CREATE TABLE IF NOT EXISTS ChicagoParkingTickets AS SELECT * FROM df1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `show()` function on a table allows us to see data in the table. By default, we only pull in a few rows--which is good, as this table is pretty big!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table(\"ChicagoParkingTickets\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DESCRIBE` keyword provides us important metadata for our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"DESCRIBE ChicagoParkingTickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuckDB is intended for analytics, as we can see with the `SUMMARIZE` keyword. This provides us a quick descriptive analysis of numeric and string data types. For numbers, we get a five-number summary, as well as approximate distinct count, mean, and actual count.\n",
    "\n",
    "Note that the approximate unique count does **not** use HyperLogLog, so it can be a little bit off. Here, it's off by approximately 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SUMMARIZE ChicagoParkingTickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing a large table can take a while, so we can perform this one time and write the results into a separate table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"CREATE OR REPLACE TABLE cpt_summary AS SELECT * FROM (SUMMARIZE ChicagoParkingTickets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuckDB supports a wide variety of ANSI SQL statements and patterns itself after PostgreSQL. In general, if it's a common part of ANSI SQL, you'll likely find it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT COUNT(*) FROM ChicagoParkingTickets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM cpt_summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common (and Uncommon) Syntax\n",
    "\n",
    "This example uses CASE expressions and aggregate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        Police_District,\n",
    "        CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END AS License_Plate_State,\n",
    "        SUM(PaymentIsOutstanding) AS TicketsOutstanding\n",
    "    FROM ChicagoParkingTickets\n",
    "    GROUP BY\n",
    "            Police_District,\n",
    "            CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END\n",
    "    ORDER BY SUM(PaymentIsOutstanding) DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting and Unpivoting\n",
    "\n",
    "DuckDB supports pivoting using the standard ANSI SQL `PIVOT` keyword, but it also has its (vast) simplification of the problem. Here, we pivot the `records` table on license plate state, getting the count of in-state tickets and out-of-state tickets by police district.\n",
    "\n",
    "We can also make use of common table expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    WITH records AS (\n",
    "    SELECT\n",
    "        Police_District,\n",
    "        CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END AS License_Plate_State,\n",
    "        SUM(PaymentIsOutstanding) AS TicketsOutstanding\n",
    "    FROM ChicagoParkingTickets\n",
    "    GROUP BY\n",
    "            Police_District,\n",
    "            CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END\n",
    "    )\n",
    "    PIVOT records\n",
    "    ON License_Plate_State\n",
    "    USING SUM(TicketsOutstanding)\n",
    "    ORDER BY Police_District\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pivot on a subset of our data. In this case, we look only at specific police districts, ignoring the rest of the data. Then, our pivot gets the count of tickets for in-state and out-of-state vehicles in each of those districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    WITH records AS (\n",
    "    SELECT\n",
    "        Police_District,\n",
    "        CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END AS License_Plate_State,\n",
    "        SUM(PaymentIsOutstanding) AS TicketsOutstanding\n",
    "    FROM ChicagoParkingTickets\n",
    "    GROUP BY\n",
    "            Police_District,\n",
    "            CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END\n",
    "    )\n",
    "    PIVOT records\n",
    "    ON Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "    USING SUM(TicketsOutstanding)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"    \n",
    "    WITH records AS (\n",
    "        SELECT\n",
    "            Police_District,\n",
    "            License_Plate_State,\n",
    "            PaymentIsOutstanding\n",
    "        FROM ChicagoParkingTickets\n",
    "    )\n",
    "    PIVOT records\n",
    "    ON Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "    USING SUM(PaymentIsOutstanding)\n",
    "    ORDER BY License_Plate_State\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common problem with pivoting is when you need more than one aggregate in your pivot. DuckDB handles that easily and auto-generates column names to make it clear which output is which."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"    \n",
    "    WITH records AS (\n",
    "        SELECT\n",
    "            Police_District,\n",
    "            Officer_ID,\n",
    "            License_Plate_State,\n",
    "            PaymentIsOutstanding\n",
    "        FROM ChicagoParkingTickets\n",
    "    )\n",
    "    PIVOT records\n",
    "    ON Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "    USING SUM(PaymentIsOutstanding), MAX(Officer_ID)\n",
    "    ORDER BY License_Plate_State\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpivoting is also possible using the `UNPIVOT` keyword. Like `PIVOT`, you can follow the ANSI SQL syntax if you so desire, but DuckDB includes a simplified version of the syntax.\n",
    "\n",
    "### Specifying Columns and Aliases\n",
    "\n",
    "We can also use the `COLUMNS()` function to specify a list of columns based on some criteria. In this case, we want to include all columns, excluding license plate state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"    \n",
    "    WITH records AS (\n",
    "        SELECT\n",
    "            Police_District,\n",
    "            License_Plate_State,\n",
    "            PaymentIsOutstanding\n",
    "        FROM ChicagoParkingTickets\n",
    "    ),\n",
    "    pivoted AS (\n",
    "        PIVOT records\n",
    "        ON Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "        USING SUM(PaymentIsOutstanding)\n",
    "    )\n",
    "    UNPIVOT pivoted\n",
    "    ON COLUMNS(* EXCLUDE(License_Plate_State))\n",
    "    INTO\n",
    "        NAME Police_District\n",
    "        VALUE PaymentIsOutstanding\n",
    "    ORDER BY Police_District ASC\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that may not be familiar to users of SQL Server or other relational database platforms is that you can alias a column in the `SELECT` clause and use that alias in other clauses, such as `WHERE`, `GROUP BY`, or `HAVING`.\n",
    "\n",
    "You can **not** use these aliases in the `ON` clause of a join, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        Police_District AS pd,\n",
    "        CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END AS License_Plate_State,\n",
    "        SUM(PaymentIsOutstanding) AS TicketsOutstanding\n",
    "    FROM ChicagoParkingTickets\n",
    "    WHERE\n",
    "        pd IN (1.0, 2.0, 3.0, 4.0)\n",
    "    GROUP BY\n",
    "        pd,\n",
    "        CASE WHEN License_Plate_State = 'IL' THEN 'In-State' ELSE 'Out-of-State' END\n",
    "    ORDER BY TicketsOutstanding DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `COLUMNS()` function also allows you to pass in lambda expressions, explaining what the shape of the set of columns should look like. For example, in this query, we retrieve the police district as well as all columns that start with the letters \"Per.\"\n",
    "\n",
    "Note that you cannot use `COLUMNS()` in the GROUP BY clause, so if you need to aggregate, you need to specify all of the columns out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        Police_District AS pd,\n",
    "        COLUMNS(col -> col LIKE 'Per%')\n",
    "    FROM ChicagoParkingTickets\n",
    "    WHERE\n",
    "        pd IN (1.0, 2.0, 3.0, 4.0)\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trailing Commas and Function Chaining\n",
    "\n",
    "DuckDB has two quality of life improvements over most implementations of ANSI SQL. The first is that, like Python, it is not choosy about trailing commas. This makes it easier to change the order of your columns without needing to add or remove commas, or deal with ugly preceding commas.\n",
    "\n",
    "The other is the ability to chain scalar functions. Instead of `TRIM(REPLACE(UPPER(Sector), ' ', '_'))`, you can chain each function using dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        Sector,\n",
    "        Sector.upper().replace(' ', '_').trim() AS Sector_upper,\n",
    "    FROM ChicagoParkingTickets\n",
    "    WHERE\n",
    "        Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins and Lateral Operations\n",
    "\n",
    "Now we will re-shape and extend our data to allow for joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE LicensePlateState\n",
    "    (\n",
    "        State_Abbreviation VARCHAR,\n",
    "        Region VARCHAR\n",
    "    );\n",
    "        \n",
    "    INSERT INTO LicensePlateState\n",
    "    SELECT DISTINCT\n",
    "        License_Plate_State,\n",
    "        CASE WHEN License_Plate_State IN ('IL') THEN 'In-State'\n",
    "             WHEN License_Plate_State IN ('IN', 'WI', 'MI', 'MO', 'IA', 'KY') THEN 'Neighbors'\n",
    "             WHEN License_Plate_State IN ('AB', 'BC', 'GU', 'MB', 'MX', 'NB', 'NF', 'NS', 'ON', 'PE', 'PQ', 'PR', 'QU', 'XX', 'YT', 'ZZ') THEN 'Out-Of-Country'\n",
    "             ELSE 'In-Country'\n",
    "        END AS Region\n",
    "    FROM ChicagoParkingTickets;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE CommunityDetails\n",
    "    (\n",
    "        Community_Name VARCHAR,\n",
    "        Sector VARCHAR,\n",
    "        Side VARCHAR,\n",
    "        Hardship_Index DOUBLE,\n",
    "        Per_capita_income DOUBLE,\n",
    "        Percent_unemployed DOUBLE,\n",
    "        Percent_without_diploma DOUBLE,\n",
    "        Percent_households_below_poverty DOUBLE,\n",
    "    );\n",
    "        \n",
    "    INSERT INTO CommunityDetails\n",
    "    SELECT DISTINCT\n",
    "        Community_Name,\n",
    "        Sector,\n",
    "        Side,\n",
    "        Hardship_Index,\n",
    "        Per_capita_income,\n",
    "        Percent_unemployed,\n",
    "        Percent_without_diploma,\n",
    "        Percent_households_below_poverty\n",
    "    FROM ChicagoParkingTickets;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuckDB supports all of the classic ANSI SQL joins, `INNER`, `LEFT OUTER`, `RIGHT OUTER`, `FULL OUTER`, and `CROSS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        lps.Region,\n",
    "        COUNT(*) AS NumberOfTickets,\n",
    "        SUM(cpt.PaymentIsOutstanding) AS TotalOutstanding,\n",
    "        CAST(100.0 * SUM(cpt.PaymentIsOutstanding) / COUNT(*) AS DECIMAL(5,2)) AS PctOutstanding\n",
    "    FROM ChicagoParkingTickets AS cpt\n",
    "        INNER JOIN LicensePlateState AS lps\n",
    "            ON cpt.License_Plate_State = lps.State_Abbreviation\n",
    "    GROUP BY\n",
    "        lps.Region\n",
    "    ORDER BY\n",
    "        lps.Region;\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start a query with the `FROM` clause and add your `SELECT` clause later. If you do not include a `SELECT` clause, DuckDB will add an implicit `SELECT *`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    FROM LicensePlateState AS lps\n",
    "    ORDER BY\n",
    "        lps.State_Abbreviation;\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do choose to put the `SELECT` clause in later, note that it comes after `FROM` and any joins, but before `WHERE`. DuckDB supports the standard SQL ordering otherwise: `WHERE`, then `GROUP BY`, `HAVING`, `ORDER BY`, and `LIMIT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    FROM ChicagoParkingTickets AS cpt\n",
    "        INNER JOIN LicensePlateState AS lps\n",
    "            ON cpt.License_Plate_State = lps.State_Abbreviation\n",
    "    SELECT\n",
    "        lps.Region,\n",
    "        COUNT(*) AS NumberOfTickets,\n",
    "        SUM(cpt.PaymentIsOutstanding) AS TotalOutstanding,\n",
    "        CAST(100.0 * SUM(cpt.PaymentIsOutstanding) / COUNT(*) AS DECIMAL(5,2)) AS PctOutstanding\n",
    "    WHERE\n",
    "        lps.Region = 'In-State'\n",
    "    GROUP BY\n",
    "        lps.Region\n",
    "    ORDER BY\n",
    "        lps.Region;\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results, as you would expect, will be the same regardless of whether you put `FROM` first or `SELECT` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        lps.Region,\n",
    "        COUNT(*) AS NumberOfTickets,\n",
    "        SUM(cpt.PaymentIsOutstanding) AS TotalOutstanding,\n",
    "        CAST(100.0 * SUM(cpt.PaymentIsOutstanding) / COUNT(*) AS DECIMAL(5,2)) AS PctOutstanding\n",
    "    FROM ChicagoParkingTickets AS cpt\n",
    "        INNER JOIN LicensePlateState AS lps\n",
    "            ON cpt.License_Plate_State = lps.State_Abbreviation\n",
    "    WHERE\n",
    "        lps.Region = 'In-State'\n",
    "    GROUP BY\n",
    "        lps.Region\n",
    "    ORDER BY\n",
    "        lps.Region;\n",
    "\"\"\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANSI SQL equivalent of T-SQL's `APPLY` operator is the `LATERAL` operator. DuckDB supports this.\n",
    "\n",
    "The basic idea of the `LATERAL` operator is, for each element on the left-hand side, we execute the function or expression in parentheses and make that the right-hand side.\n",
    "\n",
    "In this case, we build up a quick table with values ranging from 0-4 inclusive as our left-hand side, and call that column `i`. Then, for each value of `i`, we add 1 to it and call it `j`.\n",
    "\n",
    "Similar to the `APPLY` operator in T-SQL, we don't explicitly join our two sets, but we do need a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        range(5) t(i),\n",
    "        LATERAL (SELECT i + 1) t2(j);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a `LATERAL` operator can be zero or more records. If we have multiple records, it's equivalent to a join with multiple matching rows on the right-hand side for a given record on the left-hand side.\n",
    "\n",
    "We can also use `ORDER BY ALL` to order by each column, without needing to specify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        generate_series(0, 2) t(i),\n",
    "        LATERAL (SELECT i + 10 UNION ALL SELECT i + 100) t2(j)\n",
    "    ORDER BY ALL;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional joins are a way of ensuring a one to one match between two tables. The concept here is that we want the first record from t1 to match the first record from t2, the second record from t1 to match the second record from t2, and so on. But we don't have any explicit join criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE t1 (x INTEGER);\n",
    "    CREATE OR REPLACE TABLE t2 (s VARCHAR);\n",
    "\n",
    "    INSERT INTO t1 VALUES (1), (2), (3);\n",
    "    INSERT INTO t2 VALUES ('a'), ('b');\n",
    "\n",
    "    SELECT *\n",
    "    FROM t1\n",
    "    POSITIONAL JOIN t2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can include tables in `LATERAL` operations, not just expressions. In this example, we retrieve the largest value of s from a given table based on matching our records CTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "    WITH records AS\n",
    "    (\n",
    "        SELECT *\n",
    "        FROM t1\n",
    "        POSITIONAL JOIN t2\n",
    "    )        \n",
    "    SELECT *\n",
    "    FROM range(5) t(i),\n",
    "        LATERAL (SELECT s FROM records WHERE t.i = records.x ORDER BY s DESC LIMIT 1) AS t2(s);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for Polars\n",
    "\n",
    "DuckDB's Python API has native support for Polars DataFrames, not just Pandas. Here, we create a DataFrame called `df` and query directly from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, 3, 4, 5],\n",
    "        \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n",
    "        \"B\": [5, 4, 3, 2, 1],\n",
    "        \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n",
    "    }\n",
    ")\n",
    "duckdb.sql(\"SELECT * FROM df\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert a DuckDB result set into a Polars (or Pandas) DataFrame, allowing us to use any functions or methods in either of those libraries on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = duckdb.sql(\"\"\"\n",
    "    SELECT 1 AS id, 'banana' AS fruit\n",
    "    UNION ALL\n",
    "    SELECT 2, 'apple'\n",
    "    UNION ALL\n",
    "    SELECT 3, 'mango'\"\"\"\n",
    ").pl()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Query Plans\n",
    "\n",
    "In case you want to understand the performance profile of a given query, DuckDB has the `explain()` function in the Python API, as well as the `EXPLAIN` keyword in the core language.\n",
    "\n",
    "This generates a pretty printed or graphical output (depending on your interface) that shows step by step what the query engine is doing to build your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAIN plan\n",
    "con.sql(\"\"\"\n",
    "    WITH records AS (\n",
    "        SELECT\n",
    "            Police_District,\n",
    "            License_Plate_State,\n",
    "            PaymentIsOutstanding\n",
    "        FROM ChicagoParkingTickets\n",
    "    ),\n",
    "    pivoted AS (\n",
    "        PIVOT records\n",
    "        ON Police_District IN (1.0, 2.0, 3.0, 4.0)\n",
    "        USING SUM(PaymentIsOutstanding)\n",
    "    )\n",
    "    UNPIVOT pivoted\n",
    "    ON COLUMNS(* EXCLUDE(License_Plate_State))\n",
    "    INTO\n",
    "        NAME Police_District\n",
    "        VALUE PaymentIsOutstanding\n",
    "    ORDER BY Police_District ASC\n",
    "\"\"\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Data Deletion\n",
    "\n",
    "Data management and deletion in DuckDB is a bit different from major database systems. In this case, we'll create a new copy of our Chicago Parking Tickets data and load it into the chicago.db file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"CREATE TABLE ChicagoParkingTickets_DELETEME AS SELECT * FROM df1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the data file on disk, we can see that the size has approximately doubled.\n",
    "\n",
    "Now let's drop that table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"DROP TABLE ChicagoParkingTickets_DELETEME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this creates a write-ahead log (.wal) file rather than actually deleting data. The file size is still ~3.0 GB.\n",
    "\n",
    "One way to clean up data in PostgreSQL is to run the vacuum command. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"VACUUM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this does nothing and, in fact, `VACUUM` is essentially a no-op in DuckDB, there simply for compatibility purposes.\n",
    "\n",
    "Instead, we want to use the `CHECKPOINT` command to flush any insert, update, or delete operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"CHECKPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even so, this still doesn't change the size of our file!\n",
    "\n",
    "If file size is a concern (and it may not be, given the way we normally work with DuckDB), you can make a copy of the existing data to a new file. This will ignore any deleted tuples and only move active data.\n",
    "\n",
    "The first step we'll perform is to make sure there is a file called chicago2.db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the database exists\n",
    "con2 = duckdb.connect(\"../duckdbdata/chicago2.db\")\n",
    "con2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll close the chicago.db connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the global module, we'll attach chicago2 and chicago as db2 and db1, respectively. Then, we'll copy the active contents of db1 into db2.\n",
    "\n",
    "This will take a little bit of time, but when it's done, db2 will be approximately 1.5 GB, exactly what we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.execute(\"\"\"\n",
    "    ATTACH '../duckdbdata/chicago2.db' AS db2;\n",
    "    ATTACH '../duckdbdata/chicago.db' AS db1;\n",
    "    COPY FROM DATABASE db1 to db2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB Extensions\n",
    "\n",
    "Like PostgreSQL, DuckDB has a variety of extensions. The DuckDB team is responsible for some of these, but there are also community extensions that you can install. There are dozens of extensions available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM duckdb_extensions()\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing an extension is very simple. After we install an extension, we can load it to make use of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"INSTALL spatial; LOAD spatial;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to see which extensions you have installed, there's a function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM duckdb_extensions() WHERE installed = true\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of the Spatial extension and take advantage of spatial queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT ST_AsGeoJSON('POLYGON((0 0, 0 1, 1 1, 1 0, 0 0))'::GEOMETRY);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"\"\"\n",
    "    SELECT CAST({\n",
    "        type: 'Feature', \n",
    "        geometry: ST_AsGeoJSON(ST_Point(1,2)), \n",
    "        properties: { \n",
    "            name: 'my_point' \n",
    "        } \n",
    "    } AS JSON) AS geojson;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT st_distance('POINT(0 0)'::GEOMETRY, 'POINT(3 3.15)'::GEOMETRY);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Injection\n",
    "\n",
    "Like any other data platform, DuckDB is susceptible to SQL injection if you write injectable code.\n",
    "\n",
    "In this example, we have two functions that write out the input `x`. The first function directly writes `x` without any type of sanitization. The second function uses a parameterized query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_duckdb_sql_injectable(x):\n",
    "    \"\"\"\n",
    "    This function is an example of how to run a SQL query with an injectable parameter.\n",
    "    It uses the DuckDB Python API to execute the SQL query and return the result.\n",
    "    \"\"\"\n",
    "    con = duckdb.connect(\"../duckdbdata/chicago.db\")\n",
    "    result = con.execute(f\"SELECT {x} as X\").fetchall()\n",
    "    con.close()\n",
    "    return result\n",
    "\n",
    "def run_duckdb_sql_parameter(x):\n",
    "    \"\"\"\n",
    "    This function is an example of how to run a SQL query with a parameter.\n",
    "    It uses the DuckDB Python API to execute the SQL query and return the result.\n",
    "    \"\"\"\n",
    "    con = duckdb.connect(\"../duckdbdata/chicago.db\")\n",
    "    result = con.execute(\"SELECT ? as X\", (x,)).fetchall()\n",
    "    con.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run these two queries with a reasonable value, we get back a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_duckdb_sql_injectable(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_duckdb_sql_parameter(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if I run the injectable query with an arbitrary SQL command, I can escape out of the query and run my own query, such as retrieving all of the DuckDB settings or even secrets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_duckdb_sql_injectable(\"42; FROM duckdb_settings();--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with the parametrized query, we cannot escape the parameter, and thus our query is safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_duckdb_sql_parameter(\"42; FROM duckdb_settings();--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
